{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem."
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import csv\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "import re \n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import ast \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score\n",
    "import eval_metrics as em\n",
    "from sklearn.metrics import recall_score, balanced_accuracy_score\n",
    "\n",
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "GOOGLE_API_KEY= ''\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"./goemotion_data/sample.csv\")\n",
    "example = pd.read_csv(\"./goemotion_data/example.csv\")\n",
    "example_dict = json.load(open(\"./goemotion_data/examples_dict.json\"))\n",
    "unique_labels = [\"neutral\", \"admiration\", \"gratitude\", \"approval\", \"amusement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_sample_probs = {}\n",
    "for i in range(210):\n",
    "    amb_labels = []\n",
    "    emotion_counts = Counter(sample.loc[i,\"human_label\"].split(\",\"))\n",
    "    total_counts = sum(emotion_counts.values())\n",
    "    probs = {emo: round(emotion_counts[emo] / total_counts, 4) for emo in unique_labels}\n",
    "    gt_sample_probs[sample.loc[i,\"id\"]] = [probs[emo] for emo in unique_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_sampling(example, example_dict, num):\n",
    "    multi_num = num//3 + 1\n",
    "    single_num = num - multi_num\n",
    "\n",
    "    multi_df = example[example['type'] == 2]\n",
    "    single_df = example[example['type'] == 1]\n",
    "\n",
    "    multi_index = multi_df.sample(multi_num,  random_state=10, weights='weights')\n",
    "    single_index = single_df.sample(single_num,  random_state=10, weights = 'weights')\n",
    "\n",
    "    cur_example_df = pd.concat([multi_index, single_index]).reset_index()\n",
    "\n",
    "    example_text = \"Example: \\n\" + \"\\n\".join(f\"Example {i+1}: {cur_example_df.loc[i,'text']}. Emotion probabilities: {example_dict[cur_example_df.loc[i, 'id']]['emo_dict']}\" for i in list(cur_example_df.index))\n",
    "    return example_text, cur_example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text, cur_example_df = example_sampling(example, example_dict, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_GENERATE_GOEMOTION = ' '.join([\n",
    "    \"You are an emotionally-intelligent and empathetic agent.\",\n",
    "    \"You will be given a piece of text and some examples, and your task is to predict the probability of the emotion of a target text. \"\n",
    "])\n",
    "RULES = \" \".join([\n",
    "    \"Choose the emotions from [neutral, admiration, gratitude, approval, amusement]. Output statisfies the following rules\\n\",\n",
    "    \"Rule 1: Generate a dictionary of emotion probabilities in format of {'neutral': 0.1, 'admiration':0.0, 'gratitude':0.1, 'approval':0.8, 'amusement':0.0}.\",\n",
    "    \"Rule 2: Ensure the sum of probability equal to 1.\\n\",\n",
    "    \"Rule 3: Do not explain, only the dictionary.\\n\",\n",
    "    \"Please check again whether your output follows the three rules.\"\n",
    "])\n",
    "USER_PROMPT_RETRY_INSTRUCTION = \"Please only pick from the given options separated by comma.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_pred_emotion(text, example_text):\n",
    "    time.sleep(0.2)\n",
    "    prompt = SYSTEM_PROMPT_GENERATE_GOEMOTION + example_text + f\"The target text is :{text}.\" + RULES\n",
    "    response = model.generate_content(prompt)\n",
    "    return response, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_format(text):\n",
    "    match = re.search(r\"\\{.*\\}\", text)\n",
    "    if match:\n",
    "        text = match.group(0)\n",
    "    result_dict = ast.literal_eval(text)\n",
    "    return result_dict\n",
    "def dictToList(dict, unique_labels):\n",
    "    prob_list = [dict[emo] for emo in unique_labels]\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch10(turn, example_text):\n",
    "    pred_emo = {}\n",
    "    log = {}\n",
    "    for i in range(10):\n",
    "        text = sample.loc[turn*10+i, 'text']\n",
    "        ID = sample.loc[turn*10+i, 'id']\n",
    "        try:\n",
    "            response, prompt = gemini_pred_emotion(text, example_text)\n",
    "            response = response.text.strip()\n",
    "            response = identify_format(response)\n",
    "            pred_emo[ID] = dictToList(response, unique_labels)\n",
    "            log[ID] = [prompt, text, response, sample.loc[turn*10+i, 'human_label']]\n",
    "        except:\n",
    "            try: \n",
    "                time.sleep(60)\n",
    "                response, prompt = gemini_pred_emotion(text, example_text)\n",
    "                response = response.text.strip()\n",
    "                \n",
    "                response = identify_format(response)\n",
    "                pred_emo[ID] = dictToList(response, unique_labels)\n",
    "\n",
    "                log[ID] = [prompt, text, response,sample.loc[turn*10+i, 'human_label']]\n",
    "            except:\n",
    "                print(ID,'Gemini api has an error.: ', text)\n",
    "                log[ID] = [text, prompt, sample.loc[turn*10+i, 'human_label']]\n",
    "                pred_emo[ID] = [1,0,0,0,0]\n",
    "    return pred_emo, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current turn: 0\n",
      "Current turn: 1\n",
      "Current turn: 2\n",
      "Current turn: 3\n",
      "edg883j Gemini api has an error.:  Why yes that ass is flawless\n",
      "Current turn: 4\n",
      "Current turn: 5\n",
      "Current turn: 6\n",
      "Current turn: 7\n",
      "Current turn: 8\n",
      "Current turn: 9\n",
      "Current turn: 10\n",
      "Current turn: 11\n",
      "Current turn: 12\n",
      "Current turn: 13\n",
      "Current turn: 14\n",
      "Current turn: 15\n",
      "Current turn: 16\n",
      "Current turn: 17\n",
      "Current turn: 18\n",
      "Current turn: 19\n",
      "Current turn: 20\n"
     ]
    }
   ],
   "source": [
    "pred_emo_t = {}\n",
    "log_t = {}\n",
    "for turn in range(0,21):\n",
    "    print(\"Current turn:\", turn)\n",
    "    time.sleep(turn)\n",
    "    pred_emo, log = batch10(turn, example_text)\n",
    "    pred_emo_t.update(pred_emo)\n",
    "    log_t.update(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
