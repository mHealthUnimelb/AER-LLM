{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem."
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import csv\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "import re \n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import ast \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "GOOGLE_API_KEY= 'YOUR_GOOGLE_API_KEY'\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_podcast_id, audio_id_in_podcast, organ_msp = msp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Emotion prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gemini_emotion_predictor(context, cur_sentence, number_of_contexts, firstflag,audio2text, shot_type):\n",
    "    \"\"\"\n",
    "    Predicts the emotional state of a speaker based on the current input sentence and the conversational context.\n",
    "\n",
    "    Parameters:\n",
    "    context (list of dict): A list of dictionaries, each representing a previous conversational turn. Each dictionary\n",
    "                            should contain at least the keys 'speaker' and 'sentence' indicating who the speaker was\n",
    "                            and what they said, respectively.\n",
    "    cur_input (dict): A dictionary representing the current sentence to be analyzed. It should contain at least the keys\n",
    "                        'speaker' and 'sentence', similar to the dictionaries in `context`.\n",
    "    number_of_contexts (int, optional): The number of contextual entries to consider for emotion prediction. Defaults to 3. The more context, the more expensive.\n",
    "\n",
    "    Returns:\n",
    "    str: The predicted emotion for the current sentence, from a set of predefined emotions such as 'happy', 'sad',\n",
    "            'neutral', or 'angry'.\n",
    "    \"\"\"\n",
    "    # for simplicity, we just use whisper-tiny's transcription, feel free to use any transcription we provide, and you can combine them\n",
    "    prompt = prompt_context(firstflag, context, cur_sentence, audio2text, shot_type):\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    return response, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_type = \"fs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Predict the entire session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podcast  MSP-PODCAST_0001\n",
      "Gemini api has an error.:  {'id': 'MSP-PODCAST_0001_0161', 'need_prediction': 'yes', 'emotion': ['Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral'], 'groundtruth': [\"the second point is obviously the sex plays a big part in the movie. we haven't talked about it much beyond your intro.\"], 'audio': 'Audio/MSP-PODCAST_0001_0161.wav', 'speaker': '0001', 'amb_emotion': ['neu', 'neu', 'neu', 'neu', 'neu'], 'emotion_probs': [1.0, 0.0, 0.0, 0.0], 'emotion_dict': {'Neutral': 1.0}}\n",
      "Number of error counts: 1 ; Number of predictions: 15\n",
      "------------------------\n",
      "Total predictions:  16 Total ground truth: 16\n"
     ]
    }
   ],
   "source": [
    "all_pred, all_ground_truth = make_predictions(organ_msp,30, need_podcast_id, shot_type, audio_id_in_podcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(folder_path):\n",
    "\n",
    "    print(\"Total predictions: \", len(all_pred), \"Total ground truth:\", len(all_ground_truth))\n",
    "    # Write to a CSV file using a context manager\n",
    "    with open(f'./msp_prediction/{folder_path}/pred.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(all_pred)\n",
    "\n",
    "    with open(f'./msp_prediction/{folder_path}/truth.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(all_ground_truth)\n",
    "\n",
    "    json.dump(log, open(f'./msp_prediction/{folder_path}/log.json', 'w'), indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions:  4114 Total ground truth: 4114\n"
     ]
    }
   ],
   "source": [
    "save_result(\"fs_30con_with_audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
